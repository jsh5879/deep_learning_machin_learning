{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "titanic",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jsh5879/deep_learning_machine_learning/blob/master/titanic.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uH4eiAaMppbW",
        "colab_type": "code",
        "outputId": "d74af4cd-db69-427a-cb37-f634868b10f8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "#titanic\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.compose import make_column_transformer\n",
        "import tensorflow as tf\n",
        "tf.set_random_seed(777)\n",
        "from tensorflow.keras.layers import Input\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import numpy as np\n",
        "\n",
        "##########데이터 로드\n",
        "\n",
        "train_df = pd.read_excel('http://june3471.pythonanywhere.com/media/%E1%84%90%E1%85%A1%E1%84%8B%E1%85%B5%E1%84%90%E1%85%A1%E1%84%82%E1%85%B5%E1%86%A8_b0fdSDZ.xlsx', sheet_name='train')\n",
        "test_df = pd.read_excel('http://june3471.pythonanywhere.com/media/%E1%84%90%E1%85%A1%E1%84%8B%E1%85%B5%E1%84%90%E1%85%A1%E1%84%82%E1%85%B5%E1%86%A8_b0fdSDZ.xlsx', sheet_name='test')\n",
        "\n",
        "labels = ['death', 'survival']\n",
        "\n",
        "##########데이터 분석\n",
        "\n",
        "##########데이터 전처리\n",
        "\n",
        "x_train_df = train_df.drop(['name', 'ticket', 'survival'], axis=1)\n",
        "x_test_df = test_df.drop(['name', 'ticket', 'survival'], axis=1)\n",
        "y_train_df = train_df[['survival']]\n",
        "y_test_df = test_df[['survival']]\n",
        "\n",
        "print(x_train_df.head())\n",
        "print(x_train_df.columns) #Index(['pclass', 'sex', 'age', 'sibsp', 'parch', 'fare', 'embarked'], dtype='object')\n",
        "\n",
        "transformer = make_column_transformer(\n",
        "    (OneHotEncoder(), ['pclass', 'sex', 'embarked']),\n",
        "    remainder='passthrough')\n",
        "transformer.fit(x_train_df)\n",
        "x_train = transformer.transform(x_train_df)\n",
        "x_test = transformer.transform(x_test_df)\n",
        "\n",
        "y_train = y_train_df.values\n",
        "y_test = y_test_df.values\n",
        "\n",
        "print(x_train.shape)\n",
        "print(y_train.shape)\n",
        "\n",
        "##########모델 학습\n",
        "##########모델 검증\n",
        "\n",
        "input = Input(shape=(12,))\n",
        "net = Dense(units=512, activation='relu')(input)\n",
        "net = Dense(units=512, activation='relu')(net)\n",
        "net = Dense(units=1, activation='sigmoid')(input)\n",
        "model = Model(inputs=input, outputs=net)\n",
        "\n",
        "model.summary()\n",
        "\n",
        "model.compile(loss='binary_crossentropy', optimizer=Adam(lr=0.01), metrics=['accuracy'])\n",
        "model.fit(x_train, y_train, epochs=50, validation_data=(x_test, y_test)) \n",
        "\n",
        "##########모델 예측\n",
        "\n",
        "x_test = transformer.transform(pd.DataFrame([[2, 'Female', 21, 0, 1, 21.00, 'S']],\n",
        "                                                   columns=['pclass', 'sex', 'age', 'sibsp', 'parch', 'fare', 'embarked']))\n",
        "print(x_test) #[[ 0.  1.  0.  1.  0.  0.  0.  1. 21.  0.  1. 21.]]\n",
        "\n",
        "y_predict = model.predict(x_test)\n",
        "print(y_predict) #[[0.9948258]]\n",
        "print(y_predict.flatten())\n",
        "print(y_predict.flatten()[0])\n",
        "print(1 if y_predict.flatten()[0] > 0.5 else 0)\n",
        "print(labels[1 if y_predict.flatten()[0] > 0.5 else 0]) #pass"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "   pclass     sex  age  sibsp  parch   fare embarked\n",
            "0       2  Female   17      0      0  12.00        C\n",
            "1       3  Female   37      0      0   9.59        S\n",
            "2       3    Male   18      1      1  20.21        S\n",
            "3       3    Male   30      0      0   7.90        S\n",
            "4       3    Male   25      0      0   7.65        S\n",
            "Index(['pclass', 'sex', 'age', 'sibsp', 'parch', 'fare', 'embarked'], dtype='object')\n",
            "(730, 12)\n",
            "(730, 1)\n",
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_2 (InputLayer)         [(None, 12)]              0         \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 1)                 13        \n",
            "=================================================================\n",
            "Total params: 13\n",
            "Trainable params: 13\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Train on 730 samples, validate on 313 samples\n",
            "Epoch 1/50\n",
            "730/730 [==============================] - 0s 305us/sample - loss: 11.3263 - acc: 0.4397 - val_loss: 6.2321 - val_acc: 0.3450\n",
            "Epoch 2/50\n",
            "730/730 [==============================] - 0s 55us/sample - loss: 6.9804 - acc: 0.3534 - val_loss: 3.4474 - val_acc: 0.3770\n",
            "Epoch 3/50\n",
            "730/730 [==============================] - 0s 65us/sample - loss: 3.0027 - acc: 0.4137 - val_loss: 0.9334 - val_acc: 0.5144\n",
            "Epoch 4/50\n",
            "730/730 [==============================] - 0s 51us/sample - loss: 0.8035 - acc: 0.6411 - val_loss: 0.6404 - val_acc: 0.6997\n",
            "Epoch 5/50\n",
            "730/730 [==============================] - 0s 51us/sample - loss: 0.6221 - acc: 0.6959 - val_loss: 0.5312 - val_acc: 0.7220\n",
            "Epoch 6/50\n",
            "730/730 [==============================] - 0s 50us/sample - loss: 0.5564 - acc: 0.7288 - val_loss: 0.5011 - val_acc: 0.7508\n",
            "Epoch 7/50\n",
            "730/730 [==============================] - 0s 50us/sample - loss: 0.5281 - acc: 0.7493 - val_loss: 0.4907 - val_acc: 0.7636\n",
            "Epoch 8/50\n",
            "730/730 [==============================] - 0s 61us/sample - loss: 0.5149 - acc: 0.7671 - val_loss: 0.4782 - val_acc: 0.7700\n",
            "Epoch 9/50\n",
            "730/730 [==============================] - 0s 52us/sample - loss: 0.5079 - acc: 0.7781 - val_loss: 0.4798 - val_acc: 0.7668\n",
            "Epoch 10/50\n",
            "730/730 [==============================] - 0s 51us/sample - loss: 0.4970 - acc: 0.7904 - val_loss: 0.4717 - val_acc: 0.7764\n",
            "Epoch 11/50\n",
            "730/730 [==============================] - 0s 51us/sample - loss: 0.4988 - acc: 0.7781 - val_loss: 0.4623 - val_acc: 0.7732\n",
            "Epoch 12/50\n",
            "730/730 [==============================] - 0s 50us/sample - loss: 0.4867 - acc: 0.7836 - val_loss: 0.4630 - val_acc: 0.7764\n",
            "Epoch 13/50\n",
            "730/730 [==============================] - 0s 54us/sample - loss: 0.4830 - acc: 0.7781 - val_loss: 0.4590 - val_acc: 0.7891\n",
            "Epoch 14/50\n",
            "730/730 [==============================] - 0s 55us/sample - loss: 0.4819 - acc: 0.7836 - val_loss: 0.4564 - val_acc: 0.7891\n",
            "Epoch 15/50\n",
            "730/730 [==============================] - 0s 56us/sample - loss: 0.4830 - acc: 0.7932 - val_loss: 0.4562 - val_acc: 0.7891\n",
            "Epoch 16/50\n",
            "730/730 [==============================] - 0s 54us/sample - loss: 0.4850 - acc: 0.7918 - val_loss: 0.4555 - val_acc: 0.7859\n",
            "Epoch 17/50\n",
            "730/730 [==============================] - 0s 51us/sample - loss: 0.4817 - acc: 0.7849 - val_loss: 0.4556 - val_acc: 0.7732\n",
            "Epoch 18/50\n",
            "730/730 [==============================] - 0s 52us/sample - loss: 0.4749 - acc: 0.7890 - val_loss: 0.4570 - val_acc: 0.7732\n",
            "Epoch 19/50\n",
            "730/730 [==============================] - 0s 51us/sample - loss: 0.4754 - acc: 0.7918 - val_loss: 0.4683 - val_acc: 0.7700\n",
            "Epoch 20/50\n",
            "730/730 [==============================] - 0s 50us/sample - loss: 0.4843 - acc: 0.7808 - val_loss: 0.4846 - val_acc: 0.7636\n",
            "Epoch 21/50\n",
            "730/730 [==============================] - 0s 50us/sample - loss: 0.4839 - acc: 0.7836 - val_loss: 0.4565 - val_acc: 0.7700\n",
            "Epoch 22/50\n",
            "730/730 [==============================] - 0s 60us/sample - loss: 0.4701 - acc: 0.7918 - val_loss: 0.4538 - val_acc: 0.7764\n",
            "Epoch 23/50\n",
            "730/730 [==============================] - 0s 53us/sample - loss: 0.4795 - acc: 0.7753 - val_loss: 0.4670 - val_acc: 0.7668\n",
            "Epoch 24/50\n",
            "730/730 [==============================] - 0s 55us/sample - loss: 0.4791 - acc: 0.7795 - val_loss: 0.4716 - val_acc: 0.7764\n",
            "Epoch 25/50\n",
            "730/730 [==============================] - 0s 50us/sample - loss: 0.4739 - acc: 0.7863 - val_loss: 0.4533 - val_acc: 0.7764\n",
            "Epoch 26/50\n",
            "730/730 [==============================] - 0s 51us/sample - loss: 0.4704 - acc: 0.8000 - val_loss: 0.4641 - val_acc: 0.7732\n",
            "Epoch 27/50\n",
            "730/730 [==============================] - 0s 53us/sample - loss: 0.4838 - acc: 0.7753 - val_loss: 0.4539 - val_acc: 0.7732\n",
            "Epoch 28/50\n",
            "730/730 [==============================] - 0s 58us/sample - loss: 0.4779 - acc: 0.8014 - val_loss: 0.4548 - val_acc: 0.7796\n",
            "Epoch 29/50\n",
            "730/730 [==============================] - 0s 52us/sample - loss: 0.4719 - acc: 0.7795 - val_loss: 0.4556 - val_acc: 0.7955\n",
            "Epoch 30/50\n",
            "730/730 [==============================] - 0s 54us/sample - loss: 0.4723 - acc: 0.7849 - val_loss: 0.4553 - val_acc: 0.7827\n",
            "Epoch 31/50\n",
            "730/730 [==============================] - 0s 54us/sample - loss: 0.4760 - acc: 0.7836 - val_loss: 0.4548 - val_acc: 0.7827\n",
            "Epoch 32/50\n",
            "730/730 [==============================] - 0s 50us/sample - loss: 0.4759 - acc: 0.7863 - val_loss: 0.4572 - val_acc: 0.7987\n",
            "Epoch 33/50\n",
            "730/730 [==============================] - 0s 52us/sample - loss: 0.4816 - acc: 0.7822 - val_loss: 0.4575 - val_acc: 0.7764\n",
            "Epoch 34/50\n",
            "730/730 [==============================] - 0s 54us/sample - loss: 0.4703 - acc: 0.7863 - val_loss: 0.4587 - val_acc: 0.7796\n",
            "Epoch 35/50\n",
            "730/730 [==============================] - 0s 63us/sample - loss: 0.4715 - acc: 0.7849 - val_loss: 0.4676 - val_acc: 0.7764\n",
            "Epoch 36/50\n",
            "730/730 [==============================] - 0s 52us/sample - loss: 0.4718 - acc: 0.7822 - val_loss: 0.4575 - val_acc: 0.7859\n",
            "Epoch 37/50\n",
            "730/730 [==============================] - 0s 52us/sample - loss: 0.4718 - acc: 0.7890 - val_loss: 0.4598 - val_acc: 0.7732\n",
            "Epoch 38/50\n",
            "730/730 [==============================] - 0s 52us/sample - loss: 0.4741 - acc: 0.7808 - val_loss: 0.4633 - val_acc: 0.7732\n",
            "Epoch 39/50\n",
            "730/730 [==============================] - 0s 53us/sample - loss: 0.4741 - acc: 0.7808 - val_loss: 0.4560 - val_acc: 0.7827\n",
            "Epoch 40/50\n",
            "730/730 [==============================] - 0s 50us/sample - loss: 0.4642 - acc: 0.7836 - val_loss: 0.4567 - val_acc: 0.7796\n",
            "Epoch 41/50\n",
            "730/730 [==============================] - 0s 53us/sample - loss: 0.4695 - acc: 0.7932 - val_loss: 0.4574 - val_acc: 0.7955\n",
            "Epoch 42/50\n",
            "730/730 [==============================] - 0s 54us/sample - loss: 0.4742 - acc: 0.7836 - val_loss: 0.4569 - val_acc: 0.7796\n",
            "Epoch 43/50\n",
            "730/730 [==============================] - 0s 50us/sample - loss: 0.4764 - acc: 0.7781 - val_loss: 0.4689 - val_acc: 0.7764\n",
            "Epoch 44/50\n",
            "730/730 [==============================] - 0s 53us/sample - loss: 0.4764 - acc: 0.7781 - val_loss: 0.4573 - val_acc: 0.7827\n",
            "Epoch 45/50\n",
            "730/730 [==============================] - 0s 52us/sample - loss: 0.4849 - acc: 0.7863 - val_loss: 0.4583 - val_acc: 0.7732\n",
            "Epoch 46/50\n",
            "730/730 [==============================] - 0s 52us/sample - loss: 0.4728 - acc: 0.7808 - val_loss: 0.4556 - val_acc: 0.7827\n",
            "Epoch 47/50\n",
            "730/730 [==============================] - 0s 54us/sample - loss: 0.4731 - acc: 0.7795 - val_loss: 0.4612 - val_acc: 0.7796\n",
            "Epoch 48/50\n",
            "730/730 [==============================] - 0s 54us/sample - loss: 0.4651 - acc: 0.7918 - val_loss: 0.4593 - val_acc: 0.7827\n",
            "Epoch 49/50\n",
            "730/730 [==============================] - 0s 51us/sample - loss: 0.4689 - acc: 0.7863 - val_loss: 0.4574 - val_acc: 0.7859\n",
            "Epoch 50/50\n",
            "730/730 [==============================] - 0s 53us/sample - loss: 0.4683 - acc: 0.7959 - val_loss: 0.4593 - val_acc: 0.7859\n",
            "[[ 0.  1.  0.  1.  0.  0.  0.  1. 21.  0.  1. 21.]]\n",
            "[[0.87909746]]\n",
            "[0.87909746]\n",
            "0.87909746\n",
            "1\n",
            "survival\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JAA3WJzKqkLw",
        "colab_type": "code",
        "outputId": "f6857282-ac2a-4393-f630-98be97372ae1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NFajCZP7rHxx",
        "colab_type": "code",
        "outputId": "7b0d38b0-6850-41c5-fb48-e6a7b9f403d5",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 77
        }
      },
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-8c1c08d0-6237-4460-930e-c2e419a800f7\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-8c1c08d0-6237-4460-930e-c2e419a800f7\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving test_result.csv to test_result.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jtUj9LPQrWWu",
        "colab_type": "code",
        "outputId": "2cd0e813-4414-44ff-e971-fa8f5a22eadd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 822
        }
      },
      "source": [
        "import pandas as pd    \n",
        "import numpy as np\n",
        "                                                      #총 5만개\n",
        "data_train = pd.read_csv('train.csv')  #훈련          4만개\n",
        "data_test = pd.read_csv('test.csv')   #검증(테스트)   1만개\n",
        "data_check = pd.read_csv('test_result.csv')   #정답\n",
        "#print(data_train)\n",
        "\n",
        "data_train = data_train.rename(columns = {'Pclass' : 'TicketClass'})\n",
        "data_test = data_test.rename(columns = {'Pclass' : 'TicketClass'})\n",
        "\n",
        "data_train = data_train.drop(['Name','Ticket','Fare','Cabin','Embarked','Age'],axis =1)  #axis = 행중심\n",
        "data_test = data_test.drop(['Name','Age','Ticket','Fare','Cabin','Embarked'], axis =1)\n",
        "#print(data_train)\n",
        "\n",
        "#Importing LabelEncoder from Sklearn\n",
        "from sklearn.preprocessing import LabelEncoder       #원핫인코딩 male = 0, female = 0\n",
        "label_encoder_sex = LabelEncoder()\n",
        "#print(data_train.head())\n",
        "#print(data_test.head())\n",
        "\n",
        "# Transforming sex column values using label Encoder\n",
        "data_train.iloc[:,3]  = label_encoder_sex.fit_transform(data_train.iloc[:,3])    #인덱스기준 모든행 3열을 라벨인코디하겠다\n",
        "data_test.iloc[:,2] = label_encoder_sex.fit_transform(data_test.iloc[:,2])\n",
        "\n",
        "data_train = data_train[['PassengerId','Sex','SibSp','Parch','TicketClass','Survived']]\n",
        "data_test = data_test[['PassengerId','Sex','SibSp','Parch','TicketClass']]\n",
        "print(data_train.head())\n",
        "\n",
        "X_train = data_train.iloc[:,0:5]   # Inputs\n",
        "Y_train = data_train.iloc[:,5]     #Output (Survived)\n",
        "print(X_train.head()) # dataframe 일 경우\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler  #0~1사이로 스케일링 #https://datascienceschool.net/view-notebook/f43be7d6515b48c0beb909826993c856/\n",
        "sc = StandardScaler()\n",
        "X_train = sc.fit_transform(X_train)\n",
        "X_test = sc.fit_transform(data_test)\n",
        "#numpy디버깅 >> 행, 열로\n",
        "print(X_train[:5, :])  #[[행, 열]] 일 경우\n",
        "print(X_test[:5, :])  #[[행, 열]] 일 경우\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Dense(13, input_dim=5, activation='relu'))\n",
        "model.add(Dense(2, activation='relu'))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "model.fit(X_train, Y_train, batch_size=10, epochs=10)\n",
        "\n",
        "# 단순 테스트\n",
        "pred = np.array([[-1.70305005,  0.75592895, -0.49947002, -0.4002477,  0.87348191]])\n",
        "print(model.predict(pred))\n",
        "\n",
        "#getting predictions of test data\n",
        "prediction = classifier.predict(X_test).tolist()\n",
        "# list to series\n",
        "se = pd.Series(prediction)\n",
        "# creating new column of predictions in data_check dataframe\n",
        "data_check['check'] = se\n",
        "data_check['check'] = data_check['check'].str.get(0)\n",
        "\n",
        "series = []\n",
        "for val in data_check.check:\n",
        "    if val >= 0.5:\n",
        "        series.append(1)\n",
        "    else:\n",
        "        series.append(0)\n",
        "data_check['final'] = series\n",
        "\n",
        "match = 0\n",
        "nomatch = 0\n",
        "for val in data_check.values:\n",
        "    if val[1] == val[3]:\n",
        "        match = match +1\n",
        "    else:\n",
        "        nomatch = nomatch +1\n",
        "\n",
        "print('match : ',match)\n",
        "print('nomatch : ',nomatch)\n",
        "print('accuracy : ',match/(match + nomatch)*100,'%')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "   PassengerId  Sex  SibSp  Parch  TicketClass  Survived\n",
            "0            1    1      1      0            3         0\n",
            "1            2    0      1      0            1         1\n",
            "2            3    0      0      0            3         1\n",
            "3            4    0      1      0            1         1\n",
            "4            5    1      0      0            3         0\n",
            "   PassengerId  Sex  SibSp  Parch  TicketClass\n",
            "0            1    1      1      0            3\n",
            "1            2    0      1      0            1\n",
            "2            3    0      0      0            3\n",
            "3            4    0      1      0            1\n",
            "4            5    1      0      0            3\n",
            "[[-1.73010796  0.73769513  0.43279337 -0.47367361  0.82737724]\n",
            " [-1.72622007 -1.35557354  0.43279337 -0.47367361 -1.56610693]\n",
            " [-1.72233219 -1.35557354 -0.4745452  -0.47367361  0.82737724]\n",
            " [-1.71844431 -1.35557354  0.43279337 -0.47367361 -1.56610693]\n",
            " [-1.71455642  0.73769513 -0.4745452  -0.47367361  0.82737724]]\n",
            "[[-1.72791209  0.75592895 -0.49947002 -0.4002477   0.87348191]\n",
            " [-1.71962474 -1.32287566  0.61699237 -0.4002477   0.87348191]\n",
            " [-1.71133739  0.75592895 -0.49947002 -0.4002477  -0.31581919]\n",
            " [-1.70305005  0.75592895 -0.49947002 -0.4002477   0.87348191]\n",
            " [-1.6947627  -1.32287566  0.61699237  0.61989583  0.87348191]]\n",
            "Epoch 1/10\n",
            "891/891 [==============================] - 0s 421us/step - loss: 0.6917 - acc: 0.6375\n",
            "Epoch 2/10\n",
            "891/891 [==============================] - 0s 123us/step - loss: 0.6327 - acc: 0.7486\n",
            "Epoch 3/10\n",
            "891/891 [==============================] - 0s 128us/step - loss: 0.5608 - acc: 0.8013\n",
            "Epoch 4/10\n",
            "891/891 [==============================] - 0s 109us/step - loss: 0.5138 - acc: 0.8058\n",
            "Epoch 5/10\n",
            "891/891 [==============================] - 0s 108us/step - loss: 0.4837 - acc: 0.8036\n",
            "Epoch 6/10\n",
            "891/891 [==============================] - 0s 107us/step - loss: 0.4678 - acc: 0.8047\n",
            "Epoch 7/10\n",
            "891/891 [==============================] - 0s 107us/step - loss: 0.4564 - acc: 0.8114\n",
            "Epoch 8/10\n",
            "891/891 [==============================] - 0s 128us/step - loss: 0.4491 - acc: 0.8092\n",
            "Epoch 9/10\n",
            "891/891 [==============================] - 0s 131us/step - loss: 0.4450 - acc: 0.8103\n",
            "Epoch 10/10\n",
            "891/891 [==============================] - 0s 128us/step - loss: 0.4430 - acc: 0.8092\n",
            "[[0.09559816]]\n",
            "match :  412\n",
            "nomatch :  6\n",
            "accuracy :  98.56459330143541 %\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}